{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a533b09-69e3-445f-ac01-8b43929f82d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02cb4e02-0352-4c79-b5ed-99eeadb4d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open(\"rocities.txt\", \"r\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e6c3114-61f0-4c6b-bd71-a699c27c4a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "count_chars = len(chars)\n",
    "stoi = {s: i + 1 for i,s in enumerate(chars)}\n",
    "stoi['*'] = 0\n",
    "itos = {i: s for s,i in stoi.items()}\n",
    "count_all_chars = len(stoi.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b2ab67-df41-4171-890e-350bc83761f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5af24f8b-adaa-44ac-842e-01a2e28bad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca54323e-9c70-42fb-b955-87f1e962f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words[:1]:\n",
    "    word = ['*'] + list(word) + ['*']\n",
    "    for ch1, ch2 in zip(word,word[1:]):\n",
    "        r = stoi[ch1]\n",
    "        c = stoi[ch2]\n",
    "        inputs.append(r)\n",
    "        targets.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8366ac9-15e5-4b22-9fca-0fc1503b22f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  4,  1, 10, 11,  9, 11, 19,  8, 23, 15, 11]),\n",
       " tensor([ 4,  1, 10, 11,  9, 11, 19,  8, 23, 15, 11,  0]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor(inputs)\n",
    "targets = torch.tensor(targets)\n",
    "inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3de77f9d-9ab4-4f0f-bb8f-63fb8eb4f5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 31])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "# one-hot encode the int tensors\n",
    "xenc = F.one_hot(inputs, num_classes=count_all_chars)\n",
    "print(xenc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aee09fed-8a2e-4b7d-b649-bcd339b8b02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f832ceab810>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efc3529f-8b1d-435d-bd26-cac5e3cc0519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(xenc.dtype)\n",
    "# for nn we need float\n",
    "xenc = xenc.float()\n",
    "print(xenc.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "802e22cc-ea75-483f-b031-92df799da062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1066e+00],\n",
       "        [ 1.4413e+00],\n",
       "        [ 6.4801e-01],\n",
       "        [-1.8258e+00],\n",
       "        [ 6.7701e-01],\n",
       "        [-2.6204e-01],\n",
       "        [ 5.7082e-01],\n",
       "        [-1.1707e+00],\n",
       "        [ 1.5221e+00],\n",
       "        [-7.4402e-01],\n",
       "        [ 1.1818e+00],\n",
       "        [-5.3148e-01],\n",
       "        [ 9.8551e-01],\n",
       "        [ 6.1625e-01],\n",
       "        [ 6.3127e-01],\n",
       "        [-8.1725e-01],\n",
       "        [ 2.0809e+00],\n",
       "        [ 1.5024e+00],\n",
       "        [-3.7580e-01],\n",
       "        [-2.3924e-01],\n",
       "        [-1.4660e+00],\n",
       "        [ 2.2441e+00],\n",
       "        [ 7.7324e-01],\n",
       "        [-1.1087e+00],\n",
       "        [ 9.4468e-02],\n",
       "        [-4.8750e-01],\n",
       "        [ 9.4507e-01],\n",
       "        [ 3.6849e-01],\n",
       "        [-1.1427e+00],\n",
       "        [-1.5951e-03],\n",
       "        [-6.2787e-01]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn(size=(count_all_chars, 1))\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9307197-48de-4851-bc7c-2f01718148e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1066],\n",
       "        [ 0.6770],\n",
       "        [ 1.4413],\n",
       "        [ 1.1818],\n",
       "        [-0.5315],\n",
       "        [-0.7440],\n",
       "        [-0.5315],\n",
       "        [-0.2392],\n",
       "        [ 1.5221],\n",
       "        [-1.1087],\n",
       "        [-0.8172],\n",
       "        [-0.5315]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d00c3ce-4427-47df-a82a-0020583b2d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6095,  0.1643, -1.8273, -0.5250,  0.8390, -0.3782, -0.0610, -0.4065,\n",
       "         -0.0264, -0.0643,  2.4813, -1.8960, -0.1972, -0.1574, -0.4759, -2.5612,\n",
       "         -0.1249, -0.0748,  0.3756,  0.4354,  1.1458, -0.3769,  1.0774,  1.2276,\n",
       "          0.5052,  3.3019,  1.2592,  1.0743,  1.0259, -1.0161,  0.2411],\n",
       "        [ 0.1571,  0.1472, -0.2804,  0.5836,  0.2204,  0.2379, -0.8709, -0.8788,\n",
       "          1.0630,  0.2674,  1.2172,  0.3791,  0.9386, -1.3777, -0.5507, -0.0157,\n",
       "          2.3314,  0.5354, -0.3529, -0.4326,  0.4138, -2.3835, -0.9140,  0.7080,\n",
       "         -0.0056,  0.5818,  0.4125, -0.1404,  0.4093,  0.1148,  0.9578],\n",
       "        [ 1.2360,  0.7968, -0.1288, -0.8328, -0.7874,  0.1000, -0.5826,  0.9550,\n",
       "         -0.1100, -0.4791, -1.4083, -0.6750,  0.0875,  0.0784,  1.5426, -0.6579,\n",
       "         -0.4705,  1.4175,  2.0805, -0.0568,  0.2056,  0.2990, -0.2630, -0.2667,\n",
       "          0.7125,  1.5019,  0.1431, -0.2221,  0.2966, -0.3424,  0.4939],\n",
       "        [-1.3549, -0.0927,  1.6302, -0.4570, -0.1868,  0.9748, -0.8843, -0.8619,\n",
       "          1.8203, -0.0739,  0.8499, -0.1533, -0.3255,  0.5139,  1.3245, -0.7581,\n",
       "         -0.1818,  0.2633, -0.2912, -1.8892,  0.1338, -0.0924,  0.5257,  1.0449,\n",
       "          0.3499, -1.3403,  2.6264, -1.4408,  1.1180, -1.9066,  0.6349],\n",
       "        [-1.7958,  0.6278, -0.0492, -1.1913,  0.4132,  1.3806, -0.5635,  1.4624,\n",
       "          1.1730, -0.4780,  0.5306,  0.4883, -0.3838, -0.1929,  1.1448, -0.2728,\n",
       "         -1.1694,  0.2635, -1.7780,  0.6237, -0.4256,  0.2516,  1.6745,  0.4712,\n",
       "          0.3638, -1.5403, -1.3137,  1.6706, -0.5250, -0.5484, -0.4592],\n",
       "        [ 0.1989, -0.2179, -1.1001,  0.0262, -0.6222, -0.3777,  1.2061,  0.1970,\n",
       "         -1.6424,  0.3078, -0.7405,  0.7877,  0.2515,  1.4093,  1.3754,  0.0975,\n",
       "         -0.2057, -0.6152, -0.8954,  0.5562, -1.0459,  0.9928, -1.2558,  0.6154,\n",
       "          1.3381,  0.3618, -1.4083, -1.2376, -0.3345,  0.3556,  0.7814],\n",
       "        [-1.7958,  0.6278, -0.0492, -1.1913,  0.4132,  1.3806, -0.5635,  1.4624,\n",
       "          1.1730, -0.4780,  0.5306,  0.4883, -0.3838, -0.1929,  1.1448, -0.2728,\n",
       "         -1.1694,  0.2635, -1.7780,  0.6237, -0.4256,  0.2516,  1.6745,  0.4712,\n",
       "          0.3638, -1.5403, -1.3137,  1.6706, -0.5250, -0.5484, -0.4592],\n",
       "        [ 0.9790, -1.0963,  0.5794, -0.3968,  0.4571, -0.0884, -0.6779,  0.5581,\n",
       "         -1.1612, -1.9924, -0.5735, -0.6462, -1.2757, -0.1253, -0.3965, -0.9482,\n",
       "          0.2950, -1.2000,  0.8262,  0.5236, -0.2933,  0.6287, -0.7374,  0.4422,\n",
       "          0.7591, -0.3474,  1.2784,  0.0067,  1.5467, -0.0866,  0.9362],\n",
       "        [ 0.0269,  0.1022, -0.7947, -0.6146, -1.1997,  0.3742, -1.6561,  2.3196,\n",
       "          0.5516, -2.2284, -1.6814, -0.8132,  0.4047,  0.6845,  1.0670,  0.4784,\n",
       "          0.5460,  0.7117,  0.2047,  0.2902, -1.8324, -0.6269, -1.8482, -0.9771,\n",
       "          0.3754, -1.1437, -1.1088, -0.6949, -1.7978,  0.0082,  0.5525],\n",
       "        [-1.1971,  1.3766, -0.0847, -0.6400,  1.5530,  0.4680, -1.4416, -2.4799,\n",
       "         -0.0166, -0.6653,  1.5509, -0.9279, -0.7993, -0.9051,  1.0243,  0.2931,\n",
       "          1.9640,  0.3102,  0.4310,  1.0898, -0.7574,  1.5001,  0.3763, -1.5156,\n",
       "         -1.3327,  1.1447, -1.3659,  0.7195,  0.1197, -0.6281,  1.2422],\n",
       "        [-0.3662, -0.0622, -0.2391,  0.5497,  0.5774,  1.3526,  0.6192, -0.2755,\n",
       "         -0.9249,  0.7566,  1.2143, -1.0612, -1.1554,  0.8977, -0.0897, -1.2775,\n",
       "          0.6006,  0.9047,  1.1827, -0.9602,  0.8361,  0.6826, -0.7786,  0.6744,\n",
       "         -1.0620,  0.8390,  2.9566,  0.0744, -1.2340,  0.1974,  1.0008],\n",
       "        [-1.7958,  0.6278, -0.0492, -1.1913,  0.4132,  1.3806, -0.5635,  1.4624,\n",
       "          1.1730, -0.4780,  0.5306,  0.4883, -0.3838, -0.1929,  1.1448, -0.2728,\n",
       "         -1.1694,  0.2635, -1.7780,  0.6237, -0.4256,  0.2516,  1.6745,  0.4712,\n",
       "          0.3638, -1.5403, -1.3137,  1.6706, -0.5250, -0.5484, -0.4592]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn(size=(count_all_chars, count_all_chars))\n",
    "xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27da8c23-1a62-4331-88eb-ecac025558f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0232, 0.0148, 0.0020, 0.0074, 0.0291, 0.0086, 0.0118, 0.0084, 0.0123,\n",
       "         0.0118, 0.1505, 0.0019, 0.0103, 0.0108, 0.0078, 0.0010, 0.0111, 0.0117,\n",
       "         0.0183, 0.0195, 0.0396, 0.0086, 0.0370, 0.0430, 0.0209, 0.3419, 0.0443,\n",
       "         0.0368, 0.0351, 0.0046, 0.0160],\n",
       "        [0.0237, 0.0234, 0.0153, 0.0363, 0.0252, 0.0257, 0.0085, 0.0084, 0.0586,\n",
       "         0.0264, 0.0683, 0.0296, 0.0517, 0.0051, 0.0117, 0.0199, 0.2083, 0.0346,\n",
       "         0.0142, 0.0131, 0.0306, 0.0019, 0.0081, 0.0411, 0.0201, 0.0362, 0.0306,\n",
       "         0.0176, 0.0305, 0.0227, 0.0527],\n",
       "        [0.0671, 0.0432, 0.0171, 0.0085, 0.0089, 0.0215, 0.0109, 0.0506, 0.0175,\n",
       "         0.0121, 0.0048, 0.0099, 0.0213, 0.0211, 0.0911, 0.0101, 0.0122, 0.0804,\n",
       "         0.1560, 0.0184, 0.0239, 0.0263, 0.0150, 0.0149, 0.0397, 0.0875, 0.0225,\n",
       "         0.0156, 0.0262, 0.0138, 0.0319],\n",
       "        [0.0044, 0.0156, 0.0871, 0.0108, 0.0142, 0.0452, 0.0070, 0.0072, 0.1053,\n",
       "         0.0158, 0.0399, 0.0146, 0.0123, 0.0285, 0.0642, 0.0080, 0.0142, 0.0222,\n",
       "         0.0128, 0.0026, 0.0195, 0.0156, 0.0289, 0.0485, 0.0242, 0.0045, 0.2359,\n",
       "         0.0040, 0.0522, 0.0025, 0.0322],\n",
       "        [0.0035, 0.0392, 0.0199, 0.0064, 0.0316, 0.0832, 0.0119, 0.0903, 0.0676,\n",
       "         0.0130, 0.0355, 0.0341, 0.0142, 0.0172, 0.0657, 0.0159, 0.0065, 0.0272,\n",
       "         0.0035, 0.0390, 0.0137, 0.0269, 0.1116, 0.0335, 0.0301, 0.0045, 0.0056,\n",
       "         0.1111, 0.0124, 0.0121, 0.0132],\n",
       "        [0.0286, 0.0189, 0.0078, 0.0241, 0.0126, 0.0161, 0.0784, 0.0286, 0.0045,\n",
       "         0.0319, 0.0112, 0.0516, 0.0302, 0.0960, 0.0928, 0.0259, 0.0191, 0.0127,\n",
       "         0.0096, 0.0409, 0.0082, 0.0633, 0.0067, 0.0434, 0.0894, 0.0337, 0.0057,\n",
       "         0.0068, 0.0168, 0.0335, 0.0512],\n",
       "        [0.0035, 0.0392, 0.0199, 0.0064, 0.0316, 0.0832, 0.0119, 0.0903, 0.0676,\n",
       "         0.0130, 0.0355, 0.0341, 0.0142, 0.0172, 0.0657, 0.0159, 0.0065, 0.0272,\n",
       "         0.0035, 0.0390, 0.0137, 0.0269, 0.1116, 0.0335, 0.0301, 0.0045, 0.0056,\n",
       "         0.1111, 0.0124, 0.0121, 0.0132],\n",
       "        [0.0668, 0.0084, 0.0448, 0.0169, 0.0396, 0.0230, 0.0127, 0.0439, 0.0079,\n",
       "         0.0034, 0.0141, 0.0132, 0.0070, 0.0221, 0.0169, 0.0097, 0.0337, 0.0076,\n",
       "         0.0573, 0.0424, 0.0187, 0.0471, 0.0120, 0.0391, 0.0536, 0.0177, 0.0901,\n",
       "         0.0253, 0.1179, 0.0230, 0.0640],\n",
       "        [0.0265, 0.0286, 0.0116, 0.0139, 0.0078, 0.0375, 0.0049, 0.2622, 0.0448,\n",
       "         0.0028, 0.0048, 0.0114, 0.0386, 0.0511, 0.0749, 0.0416, 0.0445, 0.0525,\n",
       "         0.0316, 0.0345, 0.0041, 0.0138, 0.0041, 0.0097, 0.0375, 0.0082, 0.0085,\n",
       "         0.0129, 0.0043, 0.0260, 0.0448],\n",
       "        [0.0056, 0.0728, 0.0169, 0.0097, 0.0869, 0.0293, 0.0043, 0.0015, 0.0181,\n",
       "         0.0094, 0.0867, 0.0073, 0.0083, 0.0074, 0.0512, 0.0246, 0.1310, 0.0251,\n",
       "         0.0283, 0.0547, 0.0086, 0.0824, 0.0268, 0.0040, 0.0048, 0.0577, 0.0047,\n",
       "         0.0377, 0.0207, 0.0098, 0.0636],\n",
       "        [0.0108, 0.0146, 0.0122, 0.0269, 0.0276, 0.0600, 0.0288, 0.0118, 0.0062,\n",
       "         0.0331, 0.0522, 0.0054, 0.0049, 0.0381, 0.0142, 0.0043, 0.0283, 0.0383,\n",
       "         0.0506, 0.0059, 0.0358, 0.0307, 0.0071, 0.0304, 0.0054, 0.0359, 0.2983,\n",
       "         0.0167, 0.0045, 0.0189, 0.0422],\n",
       "        [0.0035, 0.0392, 0.0199, 0.0064, 0.0316, 0.0832, 0.0119, 0.0903, 0.0676,\n",
       "         0.0130, 0.0355, 0.0341, 0.0142, 0.0172, 0.0657, 0.0159, 0.0065, 0.0272,\n",
       "         0.0035, 0.0390, 0.0137, 0.0269, 0.1116, 0.0335, 0.0301, 0.0045, 0.0056,\n",
       "         0.1111, 0.0124, 0.0121, 0.0132]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = xenc @ W  # log-counts\n",
    "counts = logits.exp()  # equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "838f5828-b4a2-4595-a647-47a04de31db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "243e3cc1-71d1-4d11-a76e-945f4bc11eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 31])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53248391-1a29-444a-92da-b241a5223eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 21\n",
    "g = torch.Generator().manual_seed(seed)\n",
    "# randomly initiate neuron weights; each neuron receives `count_all_chars` inputs\n",
    "W = torch.randn(size=(count_all_chars, count_all_chars), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a78eb1b2-9ac1-461f-b140-14af06687396",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(inputs, num_classes=count_all_chars)  # input to the network: one hot encoding\n",
    "xenc = xenc.float()\n",
    "logits = xenc @ W  # predict log-counts\n",
    "counts = logits.exp()  # equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True)  # probabilities of next char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d53a7f2-1398-48c4-af94-aaeee06415f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 31])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ade71a0-3714-43f9-9c01-e33ae16b1579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "bigram: *1\tindices: 0,4\n",
      "neural network input: 0\n",
      "output probabilities: tensor([0.0155, 0.0066, 0.0230, 0.0234, 0.0076, 0.0114, 0.0652, 0.0514, 0.0065,\n",
      "        0.0085, 0.0196, 0.0246, 0.0472, 0.0115, 0.0146, 0.0523, 0.0956, 0.0151,\n",
      "        0.0087, 0.0819, 0.1142, 0.0636, 0.0256, 0.0099, 0.0722, 0.0194, 0.0109,\n",
      "        0.0397, 0.0122, 0.0178, 0.0243])\n",
      "actual output [label]: 4\n",
      "predicted label: 0.007582372520118952\n",
      "log likelihood: -4.88192892074585\tnegative log likelihood: 4.88192892074585\n",
      "-------------------------\n",
      "-------------------------\n",
      "bigram: 1 \tindices: 4,1\n",
      "neural network input: 4\n",
      "output probabilities: tensor([0.0634, 0.0062, 0.0250, 0.0028, 0.0358, 0.0368, 0.0236, 0.0110, 0.0452,\n",
      "        0.0050, 0.1277, 0.1048, 0.1138, 0.0110, 0.0047, 0.0122, 0.0228, 0.0222,\n",
      "        0.0051, 0.0165, 0.0108, 0.0062, 0.0489, 0.0106, 0.0169, 0.0298, 0.0505,\n",
      "        0.0146, 0.0667, 0.0392, 0.0100])\n",
      "actual output [label]: 1\n",
      "predicted label: 0.006232028361409903\n",
      "log likelihood: -5.0780534744262695\tnegative log likelihood: 5.0780534744262695\n",
      "-------------------------\n",
      "-------------------------\n",
      "bigram:  D\tindices: 1,10\n",
      "neural network input: 1\n",
      "output probabilities: tensor([0.0165, 0.0121, 0.0357, 0.0096, 0.0230, 0.0164, 0.0525, 0.0120, 0.0694,\n",
      "        0.0115, 0.0139, 0.0100, 0.0269, 0.0545, 0.1260, 0.0097, 0.0182, 0.0040,\n",
      "        0.0337, 0.0113, 0.0112, 0.0229, 0.0155, 0.0443, 0.0110, 0.0306, 0.2259,\n",
      "        0.0045, 0.0072, 0.0096, 0.0502])\n",
      "actual output [label]: 10\n",
      "predicted label: 0.013875400647521019\n",
      "log likelihood: -4.277637958526611\tnegative log likelihood: 4.277637958526611\n",
      "-------------------------\n",
      "-------------------------\n",
      "bigram: DE\tindices: 10,11\n",
      "neural network input: 10\n",
      "output probabilities: tensor([0.0134, 0.0124, 0.0345, 0.0186, 0.0305, 0.1409, 0.0276, 0.0400, 0.0215,\n",
      "        0.0049, 0.0531, 0.0114, 0.0101, 0.0085, 0.0277, 0.0276, 0.0617, 0.0411,\n",
      "        0.0280, 0.0188, 0.0495, 0.0103, 0.0233, 0.0102, 0.0685, 0.0885, 0.0282,\n",
      "        0.0121, 0.0280, 0.0360, 0.0126])\n",
      "actual output [label]: 11\n",
      "predicted label: 0.011427441611886024\n",
      "log likelihood: -4.471737861633301\tnegative log likelihood: 4.471737861633301\n",
      "-------------------------\n",
      "-------------------------\n",
      "bigram: EC\tindices: 11,9\n",
      "neural network input: 11\n",
      "output probabilities: tensor([0.0024, 0.1452, 0.0549, 0.0035, 0.0033, 0.0080, 0.0053, 0.0109, 0.0029,\n",
      "        0.0696, 0.1059, 0.0065, 0.0227, 0.0070, 0.0115, 0.0028, 0.0122, 0.1001,\n",
      "        0.2129, 0.0065, 0.0393, 0.0025, 0.0438, 0.0209, 0.0193, 0.0093, 0.0230,\n",
      "        0.0179, 0.0038, 0.0192, 0.0070])\n",
      "actual output [label]: 9\n",
      "predicted label: 0.06961125135421753\n",
      "log likelihood: -2.6648290157318115\tnegative log likelihood: 2.6648290157318115\n",
      "-------------------------\n",
      "==============================\n",
      "average nll: 4.274837493896484\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "\n",
    "for i in range(5):\n",
    "    # i-th bigram\n",
    "    x = inputs[i].item()\n",
    "    y = targets[i].item()\n",
    "    print('-'*25)\n",
    "    print(f\"bigram: {itos[x]}{itos[y]}\\tindices: {x},{y}\")\n",
    "    print(f\"neural network input: {x}\")\n",
    "    print(f\"output probabilities: {probs[i]}\")\n",
    "    print(f\"actual output [label]: {y}\")\n",
    "    p = probs[i,y]\n",
    "    print(f\"predicted label: {p.item()}\")\n",
    "    \n",
    "    logp = torch.log(p)\n",
    "    nll = -logp\n",
    "    print(f\"log likelihood: {logp}\\tnegative log likelihood: {nll}\")\n",
    "    nlls[i] = nll\n",
    "    print('-'*25)\n",
    "    \n",
    "print('==='*10)\n",
    "print(f\"average nll: {nlls.mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8056fefc-5303-4ffe-a56a-e4dddcb32024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0076, 0.0062, 0.0139, 0.0114, 0.0696, 0.0035, 0.0065, 0.0158, 0.0456,\n",
       "        0.0139, 0.0638, 0.0024])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[torch.arange(12), targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f43441b7-ef94-490a-b246-fda0e19d7f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.3623)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-probs[torch.arange(12), targets].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64c3f8b5-0816-4d06-a0d8-589400b7aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 21\n",
    "gen = torch.Generator().manual_seed(seed)\n",
    "W = torch.randn((count_all_chars, count_all_chars), generator=gen, requires_grad=True)\n",
    "# forward pass\n",
    "xenc = F.one_hot(inputs, num_classes=count_all_chars).float()\n",
    "logits = xenc @ W\n",
    "\n",
    "# softmax\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "\n",
    "# backward pass\n",
    "W.grad = None  # sets grad to 0\n",
    "loss = -probs[torch.arange(12), targets].log().mean()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9eb195a-6023-4490-b204-c380741c4753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.362264633178711"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "088a8cd8-debb-4346-bcd9-8ecd4572ae33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 31])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive grad: positive influence... adding small h to it will increase the loss\n",
    "W.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "649c3719-af41-4251-8ea7-e747b8c8ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -0.1 * W.grad  # optimization step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f839612-cafd-4c74-8e46-b7c42097d66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3534674644470215"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "loss = -probs[torch.arange(12), targets].log().mean()\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b178f78a-8194-4dfa-b5a1-205c0e091250",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optimization ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf63c949-57a3-42b2-9f86-409fc1d007e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples: 98696\n"
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "targets = []\n",
    "for word in words:\n",
    "    word = ['*'] + list(word) + ['*']\n",
    "    for ch1, ch2 in zip(word,word[1:]):\n",
    "        r = stoi[ch1]\n",
    "        c = stoi[ch2]\n",
    "        inputs.append(r)\n",
    "        targets.append(c)\n",
    "inputs = torch.tensor(inputs)\n",
    "targets = torch.tensor(targets)\n",
    "num = inputs.nelement()\n",
    "print(f'number of examples: {num}')\n",
    "\n",
    "seed = 21\n",
    "gen = torch.Generator().manual_seed(seed)\n",
    "W = torch.randn((count_all_chars, count_all_chars), generator=gen, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a594ac1-b642-45a5-aace-b6a528182bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(inputs, num_classes=count_all_chars).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "af967007-0e05-4e7b-b6e0-7aaf8cbc50af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 10: 3.6901051998138428\n",
      "loss at epoch 20: 3.547089099884033\n",
      "loss at epoch 30: 3.4256863594055176\n",
      "loss at epoch 40: 3.3242759704589844\n",
      "loss at epoch 50: 3.2394282817840576\n",
      "loss at epoch 60: 3.167375087738037\n",
      "loss at epoch 70: 3.105081558227539\n",
      "loss at epoch 80: 3.050382375717163\n",
      "loss at epoch 90: 3.0017635822296143\n",
      "loss at epoch 100: 2.958153009414673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.958153009414673"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient descent\n",
    "learning_rate = 1\n",
    "epochs = 100\n",
    "for epoch in range(1,epochs+1):\n",
    "    # forward pass:\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts/counts.sum(1,keepdims=True)\n",
    "    \n",
    "    loss = -probs[torch.arange(num), targets].log().mean()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"loss at epoch {epoch}: {loss.item()}\")\n",
    "    \n",
    "    # backward pass:\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # optimization:\n",
    "    W.data += -learning_rate * W.grad\n",
    "loss.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
